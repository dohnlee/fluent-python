{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4 Text versus Bytes (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing unicode for saner comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String 간 비교는 Unicode가 성조와 같은 발음 구별 부호 문자를 갖기 때문에 다소 복잡하다. 이 부호는 앞서 나오는 문자에 붙어 하나의 글자로 보이는 특징(combining characters)을 갖는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('café', 'café')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 예시에서 `s1`과 `s2`의 결과는 같아보이지만, 파이썬은 이 둘을 다른 것으로 본다. 이러한 경우를 처리하기 위해 크게 3가지의 방법이 존재한다. \n",
    "1. `unicodedata.normalize(form, unistr)`\n",
    "2. `str.casefold()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__unicodedata.normalize(form, unistr)__  \n",
    "\n",
    "유니코드 문자열 `unistr`에 대한 정규화 형식(`form`)을 반환한다. \n",
    "- form : 'NFC', 'NFD', 'NFKC', 'NFKD' 중 하나의 값을 갖는다. \n",
    "  - Normalized Form C (NFC), Normalized Form D (NFD): 'canonical equivalance'를 위한 조정, NFD는 정준 분해라고 하며, 각 문자를 분해된 형식(base characters + combining characters)으로 변환한다. NFC는 정준 분해 적용 후, 미리 결합한 문자로 다시 조합(shortest equivalent string)한다. \n",
    "  - NFKC, NFKD: 'compatibility equivalence'를 기반으로 하는 정규화 형식. NFKD는 호환 분해를 적용한다. 즉, 모든 호환 문자를 동등한 것으로 치환한다. NFKC는 먼저 호환 분해를 적용한 후, 정준 결합을 적용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "canonical equivalence 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize('NFC', s1)), len(normalize('NFC', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalize('NFD', s1)), len(normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFC', s1) == normalize('NFC', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFD', s1) == normalize('NFD', s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compatibility equivalence 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1⁄2'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "half = '½'\n",
    "normalize('NFKC', half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('µ', 'μ')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro = 'µ'\n",
    "micro_kc = normalize('NFKC', micro)\n",
    "micro, micro_kc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 956)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(micro), ord(micro_kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MICRO SIGN', 'GREEK SMALL LETTER MU')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name(micro), name(micro_kc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFKC나 NFKD는 정보를 왜곡시킬 수도 있다. 예를 들어 4의 제곱을 `42`로 출력한다. 하지만 검색할 때, 유용하게 쓰일 수 있다. (데이터를 변형시킬 수 있기 때문에, 저장하는 용도로는 사용하지 않는 것이 좋다.) 검색할 때 유용하게 쓰이는 연산이 하나 더 있는데, 그게 'Case Folding'이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__str.casefold()__  \n",
    "  \n",
    "Case Folding은 모든 문자를 소문자로 바꿔주는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('µ', 'μ')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro = 'µ'\n",
    "micro_cf = micro.casefold()\n",
    "micro, micro_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MICRO SIGN', 'GREEK SMALL LETTER MU')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name(micro), name(micro_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ß', 'ss')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eszett = 'ß'\n",
    "eszett_cf = eszett.casefold()\n",
    "eszett, eszett_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이외에도 사람들이 발음 구별 부호를 사용하는 것을 귀찮아하거나, 까먹는다는 사실을 근거로 문자에서 그 부호를 아예 제거하여 검색하는 방법을 사용하기도 한다. 책에서는 이와 관련된 함수를 소개하지만, 여기서는 쓰인 함수에 대한 소개와 예시를 정리하려고 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 230)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "s1 = 'café'\n",
    "s1_norm = normalize('NFD', s1)\n",
    "unicodedata.combining(s1_norm[3]), unicodedata.combining(s1_norm[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wpkeqfg'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_two = str.maketrans('abcdefghijklmnopqrstuvwxyz',\n",
    "                          'cdefghijklmnopqrstuvwxyzab')\n",
    "before = 'unicode'\n",
    "after = before.translate(shift_two)\n",
    "after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting unicode text\n",
    "\n",
    "Python에서는 string을 정렬할 때, code point를 비교한다. 이러한 경우 다음 예시와 같이 ASCII 문자 외의 문자에 대하여 이상한 결과를 낳을 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acerola', 'açaí', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 해결하기 위한 일반적인 방법은 `locale.strxfrm` 함수를 이용하는 것이다. 이 함수를 적절하게 사용하기 위해서는 적절한 지역, 언어를 파악하고 운영체제가 이것을 지원하기를 기도(?)하는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.UTF-8'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acerola', 'açaí', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted(fruits, key=locale.strxfrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원하는 결과가 안 나온다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "locale.setdefault() 사용 시 주의사항\n",
    "1. locale setting은 global하게 작용하니, 처음 설정 후 바꾸지 말 것\n",
    "2. locale이 OS에 설치되어있어야 한다.\n",
    "3. locale name을 정확히 알고 있어야 한다. 표준 형태가 존재하는데 운영체제마다 형태가 다르다. \n",
    "4. locale이 OS 내에서 정상적으로 작동해야 한다. (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 방법은 GNU/Linux 기반에서만 잘 작동하는 것처럼 보인다. 다행히, 더 간단한 해결방법이 있는데 Unicode Collation Algorithm (UCA)를 이용하는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyuca in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyuca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyuca\n",
    "coll = pyuca.Collator()\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted(fruits, key=coll.sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The unicode database\n",
    "\n",
    "unicode 표준은 database를 제공하는데, 이것은 문자의 code point와 이름을 연결하는 table이나 각각의 문자에 대한 메타정보를 담고 있는 table 등을 포함하고 있고, 이를 확인할 수 있는 코드를 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 문자열이 알파벳, 숫자, 기호, space만으로 이루어져있다면 True 반환\n",
    "a = '\\u00bc'\n",
    "b = '\\u0014'\n",
    "a.isprintable(), b.isprintable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10진수로 구성되어있는지 확인\n",
    "c = '345'\n",
    "d = '0b11000'\n",
    "c.isdecimal(), d.isdecimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ⅻ', 12.0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 문자가 갖는 숫자값을 반환\n",
    "'\\u216b', unicodedata.numeric('\\u216b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual-Mode str and bytes APIs\n",
    "\n",
    "`re`와 `os` 모듈은 str과 bytes 모두를 인자로 받을 수 있고, 어떤 타입이 들어오는지에 따라 다르게 작동한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      " 'Ramanujan saw ௧௭௨௯ as 1729'\n",
      "Numbers\n",
      " str : ['௧௭௨௯', '1729']\n",
      " bytes: [b'1729']\n",
      "Words\n",
      " str : ['Ramanujan', 'saw', '௧௭௨௯', 'as', '1729']\n",
      " bytes: [b'Ramanujan', b'saw', b'as', b'1729']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "re_numbers_str = re.compile(r'\\d+')\n",
    "re_words_str = re.compile(r'\\w+')\n",
    "re_numbers_bytes = re.compile(rb'\\d+')\n",
    "re_words_bytes = re.compile(rb'\\w+')\n",
    "\n",
    "text_str = \"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef as 1729\"\n",
    "text_bytes = text_str.encode('utf-8')\n",
    "\n",
    "print('Text', repr(text_str), sep='\\n ')\n",
    "print('Numbers')\n",
    "print(' str :', re_numbers_str.findall(text_str))\n",
    "print(' bytes:', re_numbers_bytes.findall(text_bytes))\n",
    "print('Words')\n",
    "print(' str :', re_words_str.findall(text_str))\n",
    "print(' bytes:', re_words_bytes.findall(text_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASCII 외의 문자는 bytes에서 숫자로도, 단어로도 취급되지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GNU/Linux kernel은 unicode를 잘 다루지 못한다. 따라서 파일 명에 str로 decode될 수 없는 문자가 있을 경우 문제를 발생시킬 수 있다. 이 문제를 처리하기 위해 모든 os 모듈 내의 함수는 str과 bytes를 모두 인자로 받을 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Untitled.ipynb',\n",
       "  'digits-of-π.txt',\n",
       "  'chapter03-1_jinny.ipynb',\n",
       "  '.ipynb_checkpoints'],\n",
       " [b'Untitled.ipynb',\n",
       "  b'digits-of-\\xcf\\x80.txt',\n",
       "  b'chapter03-1_jinny.ipynb',\n",
       "  b'.ipynb_checkpoints'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('.'), os.listdir(b'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References  \n",
    "[unicodedata 문서](https://docs.python.org/ko/3/library/unicodedata.html)  \n",
    "[locale 문서](https://docs.python.org/3/library/locale.html?highlight=strxfrm#locale.strxfrm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
